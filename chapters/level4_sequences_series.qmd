# Level 4: Sequences and Series

## Introduction

**Lila:** Acharya, until now we have been exploring real numbers, their representations, and Cantor’s ideas. But what comes next in our journey?

**Acharya Bhaskar:** A natural next step, Lila, is to study not just *individual* numbers, but *patterns* of numbers — how they progress, how they accumulate. This leads us to the study of **sequences** and **series**.

---

## What is a sequence?

**Lila:** What exactly is a sequence?

**Acharya Bhaskar:** A **sequence** is simply an ordered list of numbers:
$$
(a_n)_{n=1}^\infty = a_1, a_2, a_3, \dots
$$
Each $a_n$ is called the *$n$-th term*. The idea is that as $n$ increases, we can watch how the terms behave — whether they approach a limit, oscillate, or grow without bound.

**Lila:** So a sequence is like watching numbers march along, step by step?

**Acharya Bhaskar:** Exactly! For example:
- $a_n = \tfrac{1}{n}$ gives the sequence $1, \tfrac{1}{2}, \tfrac{1}{3}, \dots$ which gets closer and closer to $0$.  
- $a_n = (-1)^n$ gives $-1, 1, -1, 1, \dots$ which jumps back and forth and never settles.

---

## What is a series?

**Lila:** And what about a series?

**Acharya Bhaskar:** A **series** is what we get when we add up the terms of a sequence:
$$
S = \sum_{n=1}^\infty a_n = a_1 + a_2 + a_3 + \cdots
$$

**Lila:** So if a sequence is footsteps, then a series is like adding the total distance covered?

**Acharya Bhaskar:** Well said! For example:
- The series $\sum_{n=1}^\infty \tfrac{1}{2^n} = \tfrac{1}{2} + \tfrac{1}{4} + \tfrac{1}{8} + \cdots$ converges to $1$.  
- But the series $\sum_{n=1}^\infty \tfrac{1}{n} = 1 + \tfrac{1}{2} + \tfrac{1}{3} + \cdots$ grows without bound — it diverges.

---

## Why study sequences and series?

**Lila:** Why are these so important?

**Acharya Bhaskar:** Because they are the language of approximation and analysis: 
1. Important numbers like $e$ and $\pi$ appear as limits of sequences or sums of series.  
2. Functions like $\sin x$, $\cos x$, and $e^x$ can be expressed as infinite series — that’s how we calculate them on computers!  
3. Understanding limits of sequences helps us define continuity, derivatives, and integrals.  

**Lila:** So sequences and series are the foundation stones for the rest of calculus and analysis.

**Acharya Bhaskar:** Precisely. Real analysis begins here, with the careful study of how infinite processes behave.

---

**Acharya Bhaskar (teaser):**  
“Think of a sequence as footsteps marching towards a destination.  
If the footsteps wander endlessly, the sequence diverges.  
If they march steadily towards a point, the sequence converges.  
And when you add the footsteps together, you create the story of a series.”  
## Limits of Sequences

**Lila:** Acharya, you said some sequences “converge” and some “diverge.” What exactly does it mean for a sequence to converge?

**Acharya Bhaskar:** Good question, Lila. Intuitively, a sequence **converges** if its terms get closer and closer to some fixed number, which we call the **limit**.

**Lila:** So for $a_n = \tfrac{1}{n}$, the terms $1, \tfrac{1}{2}, \tfrac{1}{3}, \dots$ get closer and closer to $0$, so the limit should be $0$?

**Acharya Bhaskar:** Exactly. We write
$$
\lim_{n\to\infty} \frac{1}{n} = 0.
$$

---

### The formal definition

**Acharya Bhaskar:** But in real analysis we need precision. So here is the definition:

A sequence $(a_n)$ is said to converge to a number $L$ if for every $\varepsilon > 0$, there exists a natural number $K(\varepsilon)$ such that whenever $n \geq K(\varepsilon)$, we have
$$
|a_n - L| < \varepsilon.
$$

**Lila:** Let me see if I understand. This means: no matter how small an error margin $\varepsilon$ I choose, if I go far enough in the sequence (beyond some $K$ that depends on the given $\varepsilon$), all terms stay within that margin around $L$.

**Acharya Bhaskar:** Well said. That is the precise meaning of convergence.

---

**Example:** $a_n = \tfrac{1}{n}$

**Lila:** Could we test this definition with $a_n = \tfrac{1}{n}$ and $L=0$?

**Acharya Bhaskar:** Certainly.  
We want: for every $\varepsilon>0$, find $K(\varepsilon)$ such that if $n\ge K(\varepsilon)$, then $|\tfrac{1}{n} - 0| < \varepsilon$.  
But $|\tfrac{1}{n} - 0| = \tfrac{1}{n}$.  
So we require $\tfrac{1}{n} < \varepsilon$.  

This is the same as $n > \tfrac{1}{\varepsilon}$.  
So if we choose $K(\varepsilon) = \lceil \tfrac{1}{\varepsilon}\rceil$, then for all $n\ge K(\varepsilon)$, the condition is satisfied.

**Lila:** That works! So the formal definition confirms that $\tfrac{1}{n} \to 0$.

---

**Example:** $a_n = (-1)^n$

**Lila:** And what about $a_n = (-1)^n$?

**Acharya Bhaskar:** Then the terms alternate $-1, 1, -1, 1, \dots$. Do they get closer to a single value?

**Lila:** No — they keep jumping back and forth. So this sequence does **not** converge.

**Acharya Bhaskar:** Correct. It diverges, because there is no single $L$ that the terms approach.

---

### Why limits matter

**Lila:** So convergence is about sequences approaching a fixed target. But why is this so important?

**Acharya Bhaskar:** Because the notion of **limit** is the cornerstone of analysis. Continuity, derivatives, integrals, and infinite series all depend on it. Mastering limits of sequences is the first step toward the deeper structures of calculus.  

**Limit of a function via sequences**

::: {.callout-note collapse="true"}
## Connecting sequence limits and function limits

**Lila:** Acharya, I understand the limit of a sequence. But what could the limit of sequences have to do with the notion of limits of functions?

**Acharya Bhaskar:** An excellent question, Lila. In fact, the two ideas are deeply connected.  

We say
$$
\lim_{x\to a} f(x) = L
$$
if and only if for **every sequence** $(x_n)$ with $x_n \to a$ and $x_n \neq a$, the sequence $(f(x_n))$ converges to $L$.

---

**Lila:** So if all possible sequences approaching $a$ give the same limiting value $L$ for $f(x_n)$, then that must be the limit of the function?

**Acharya Bhaskar:** Exactly. This is called the *sequential criterion* for functional limits.  

It tells us: instead of thinking about all the infinitely many “ways” of approaching $a$, it is enough to test every possible sequence converging to $a$.

---

**Lila:** Ah! So the concept of a function limit is really an extension of the idea of sequence limits.

**Acharya Bhaskar:** Precisely, Lila. That is why we first built a strong foundation with sequences — they are the key to understanding limits of functions.
:::

### Another Example of Convergence

**Lila:** We proved earlier that $\lim \tfrac{1}{n} = 0$. Could you show me another example, maybe a slightly different sequence?

**Acharya Bhaskar:** Certainly! Let’s consider the sequence  
$$x_n = \frac{1}{n^2+1}.$$
I claim that $\lim_{n \to \infty} x_n = 0$.

**Lila:** Oh, it looks similar to $\tfrac{1}{n}$, but the denominator grows even faster. So it should also go to zero, right?

**Acharya Bhaskar:** Exactly. Let’s do a rigorous $\varepsilon$–$N$ proof.

<details>
<summary>Click to see the proof</summary>

We want to show that for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$\Bigg|\frac{1}{n^2+1} - 0\Bigg| < \varepsilon.$$

But  
$$\Bigg|\frac{1}{n^2+1}\Bigg| = \frac{1}{n^2+1}.$$

Notice that  
$$\frac{1}{n^2+1} < \frac{1}{n^2}.$$

So it is enough to require  
$$\frac{1}{n^2} < \varepsilon.$$

This means  
$$n^2 > \frac{1}{\varepsilon}, \quad \text{or equivalently} \quad n > \frac{1}{\sqrt{\varepsilon}}.$$

Thus, if we choose  
$$N = \left\lceil \frac{1}{\sqrt{\varepsilon}} \right\rceil,$$  
then for all $n > N$,  
$$\frac{1}{n^2+1} < \varepsilon.$$

Hence,  
$$\lim_{n \to \infty} \frac{1}{n^2+1} = 0.$$

</details>

**Lila:** That was neat! So the idea is the same as before, but we had to be careful with the square root this time.

**Acharya Bhaskar:** Exactly. You’ll see that many convergence proofs follow a similar structure. The challenge is usually in rearranging inequalities smartly.

---

### A Non–Zero Limit Example

**Lila:** So far, the examples we’ve done all go to zero. Can you show me a sequence that converges to something other than zero?

**Acharya Bhaskar:** Of course. Let’s look at  
$$x_n = \frac{n}{n+1}.$$

I claim that  
$$\lim_{n \to \infty} \frac{n}{n+1} = 1.$$

**Lila:** Hmm… when $n$ is large, $n+1$ is almost the same as $n$, so $\tfrac{n}{n+1}$ should be almost $1$.

**Acharya Bhaskar:** Exactly. Now let’s prove it formally.

<details>
<summary>Click to see the proof</summary>

We want to show: for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| < \varepsilon.$$

Simplify the difference:  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| = \Bigg|\frac{n - (n+1)}{n+1}\Bigg| = \frac{1}{n+1}.$$

So we need  
$$\frac{1}{n+1} < \varepsilon.$$

That is,  
$$n+1 > \frac{1}{\varepsilon} \quad \implies \quad n > \frac{1}{\varepsilon} - 1.$$

Thus, if we choose  
$$N = \left\lceil \frac{1}{\varepsilon} - 1 \right\rceil,$$  
then for all $n > N$,  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| < \varepsilon.$$

Therefore,  
$$\lim_{n \to \infty} \frac{n}{n+1} = 1.$$

</details>

**Lila:** That was nice! The sequence actually climbs closer and closer to $1$, never quite reaching it, but the proof shows it really does converge there.

**Acharya Bhaskar:** Exactly. This illustrates an important point — limits don’t always have to be zero; the same method works for any real number.

### Convergence to a Rational Number

**Lila:** We’ve seen limits going to $0$ and $1$. Can a sequence converge to some other fraction, like $\tfrac{2}{5}$?

**Acharya Bhaskar:** Absolutely! Let’s take  
$$x_n = \frac{2n+3}{5n+1}.$$

I claim that  
$$\lim_{n \to \infty} \frac{2n+3}{5n+1} = \frac{2}{5}.$$

**Lila:** I can guess why — the higher powers of $n$ dominate, so it’s like $\tfrac{2n}{5n} = \tfrac{2}{5}$ when $n$ is large.

**Acharya Bhaskar:** That’s the intuition. Let’s now prove it rigorously.

<details>
<summary>Click to see the proof</summary>

We want to show: for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| < \varepsilon.$$

Simplify the difference:  
$$
\frac{2n+3}{5n+1} - \frac{2}{5}
= \frac{5(2n+3) - 2(5n+1)}{5(5n+1)}
= \frac{10n+15 - 10n - 2}{25n+5}
= \frac{13}{25n+5}.
$$

So  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| = \frac{13}{25n+5}.$$

Now, we want  
$$\frac{13}{25n+5} < \varepsilon.$$

This inequality is equivalent to  
$$25n+5 > \frac{13}{\varepsilon} \quad \implies \quad n > \frac{13}{25\varepsilon} - \frac{1}{5}.$$

So we can choose  
$$N = \left\lceil \frac{13}{25\varepsilon} - \frac{1}{5} \right\rceil.$$

Then for all $n > N$, we have  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| < \varepsilon.$$

Therefore,  
$$\lim_{n \to \infty} \frac{2n+3}{5n+1} = \frac{2}{5}.$$

</details>

**Lila:** I see! The algebra looks a bit longer, but the same method works. The main trick was simplifying the difference.

**Acharya Bhaskar:** Precisely. Once you bring it into a simple form, the $\varepsilon$–$N$ argument falls into place. This shows that sequences can converge to any real number, not just $0$ or $1$.

### An Example of Divergence

**Lila:** All the examples so far show sequences settling to a finite number. But what about a sequence that *doesn’t* converge?  

**Acharya Bhaskar:** Excellent question. Consider the sequence  
$$x_n = n.$$

**Lila:** That just grows bigger and bigger! So it can’t converge to a real number, right?

**Acharya Bhaskar:** Exactly. Formally, we say it *diverges to infinity*. Let’s make this precise.

<details>
<summary>Click to see the explanation</summary>

To say that $\lim_{n \to \infty} x_n = +\infty$ means:  

For every real number $M > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$x_n > M.$$

Now, since $x_n = n$, if you give me any $M > 0$, I can simply choose  
$$N = \lceil M \rceil.$$  

Then for all $n > N$, clearly $n > M$, so $x_n > M$.  

Thus, the sequence $\{n\}$ does not converge to a finite limit, but instead diverges to infinity.  

</details>

**Lila:** So divergence isn’t just “no limit at all.” Sometimes it means the sequence goes off to infinity in a systematic way.  

**Acharya Bhaskar:** Exactly. There are also examples where sequences oscillate and fail to have any limit at all — those are divergent in a different sense.  

### An Oscillating Divergent Sequence

**Lila:** You said some sequences can diverge by oscillating. Can you show me an example?

**Acharya Bhaskar:** Certainly. Consider the sequence  
$$x_n = (-1)^n.$$

**Lila:** Oh, so it goes like $-1, +1, -1, +1, \dots$ That never settles down to a single number.

**Acharya Bhaskar:** Exactly. Let’s explain why it does **not** converge.

<details>
<summary>Click to see the explanation</summary>

Suppose, for contradiction, that $\lim_{n \to \infty} (-1)^n = L$ for some real number $L$.  

Then by the definition of convergence, for every $\varepsilon > 0$ there should be an $N$ such that for all $n > N$,  
$$|(-1)^n - L| < \varepsilon.$$

But notice:  
- If $n$ is even, $(-1)^n = 1$.  
- If $n$ is odd, $(-1)^n = -1$.  

So the sequence keeps jumping between $1$ and $-1$, no matter how large $n$ becomes.  

For example, if we take $\varepsilon = \tfrac{1}{2}$, then the condition requires all terms $(-1)^n$ to lie within an interval of radius $\tfrac{1}{2}$ around $L$.  

But one subsequence is constantly $1$, and the other is constantly $-1$. These two points are $2$ units apart, which is much larger than $\tfrac{1}{2}$.  

Therefore, no single $L$ can satisfy the definition. The sequence does **not converge**.

</details>

**Lila:** I see! Unlike $n$, which runs off to infinity, this one just keeps bouncing forever without settling.

**Acharya Bhaskar:** Precisely. These two examples : $x_n = n$ and $x_n = (-1)^n$, illustrate two common ways in which sequences can fail to converge.

### Summary of Examples

In this section, we explored several examples to understand the behavior of sequences:

- Some sequences converge to **zero**, such as $\tfrac{1}{n}$ and $\tfrac{1}{n^2+1}$.  
- Others converge to **non-zero finite limits**, like $\tfrac{n}{n+1} \to 1$ and $\tfrac{2n+3}{5n+1} \to \tfrac{2}{5}$.  
- Not all sequences converge:  
  - $\{n\}$ **diverges to infinity**, growing without bound.  
  - $\{(-1)^n\}$ **oscillates**, never settling to a single value.  

These examples show that sequences may approach a finite limit, grow without bound, or fail to settle altogether. In each case, the precise $\varepsilon$–$N$ definition helps us make these ideas rigorous.

### Key Techniques for Proving Limits of Sequences

When proving convergence (or divergence), these strategies are especially useful:

- **Inequality comparison:**  
  Show $|x_n - L|$ is bounded above by a simpler expression that you can control.  
  *Example:* $\tfrac{1}{n^2+1} < \tfrac{1}{n^2}$.

- **Algebraic simplification:**  
  Rearrange the difference $x_n - L$ into a form where $n$ appears in the denominator.  
  *Example:* $\tfrac{n}{n+1} - 1 = \tfrac{-1}{n+1}$.

- **Dominant term analysis:**  
  For rational functions of $n$, compare the highest powers of $n$ in numerator and denominator.  
  *Example:* $\tfrac{2n+3}{5n+1} \to \tfrac{2}{5}$.


- **Divergence checks:**  
  - If $x_n \to \infty$, prove that for every $M > 0$, eventually $x_n > M$.  
    *Example:* $x_n = n$.  
  - If $x_n$ oscillates between two or more values that stay apart, it has **no limit**.  
    *Example:* $x_n = (-1)^n$.

These techniques will reappear often and form the backbone of rigorous $\varepsilon$–$N$ proofs.

### Motivation for the Comparison Theorem

**Lila:** In all these examples, we always end up bounding $|x_n - L|$ by something simpler that goes to zero.  
Like for $\tfrac{1}{n^2+1}$, we said it was less than $\tfrac{1}{n^2}$, and since that goes to zero, the sequence also goes to zero.

**Acharya Bhaskar:** Exactly. You’ve spotted a very general pattern.  
If we can show that the error term $|x_n - x|$ is not bigger than some *controlling sequence* that shrinks to zero, then $x_n$ must also converge to $x$.

**Lila:** So instead of always doing the $\varepsilon$–$N$ argument from scratch, we can reduce it to something we already know?

**Acharya Bhaskar:** Yes. That’s the beauty of it.  
We use one sequence $(a_n)$ that’s already known to converge to $0$, and if $|x_n - x|$ is squeezed under a constant multiple of $a_n$, then $x_n$ must converge to $x$.

**Lila:** Ah, so this is like a systematic version of the trick we’ve been using.  

**Acharya Bhaskar:** Precisely. Let me now state this as a theorem.

---

### Theorem: Controlling a Sequence by Another

**Theorem.**  
Let $(x_n)$ be a sequence of real numbers and let $x \in \mathbb{R}$.  
Suppose $(a_n)$ is a sequence of positive real numbers with $\lim_{n \to \infty} a_n = 0$.  
If there exists a constant $C > 0$ and an $m \in \mathbb{N}$ such that  
$$|x_n - x| \leq C \, a_n \quad \text{for all } n \geq m,$$  
then  
$$\lim_{n \to \infty} x_n = x.$$

<details>
<summary>Click to see the proof</summary>

We want to show that for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$|x_n - x| < \varepsilon.$$

By assumption,  
$$|x_n - x| \leq C a_n \quad \text{for all } n \geq m.$$

Since $\lim_{n \to \infty} a_n = 0$, given $\varepsilon > 0$ we know there exists $N_1 \in \mathbb{N}$ such that for all $n > N_1$,  
$$a_n < \frac{\varepsilon}{C}.$$

So, for $n > \max\{m, N_1\}$, we have  
$$|x_n - x| \leq C a_n < C \cdot \frac{\varepsilon}{C} = \varepsilon.$$

Therefore, $\lim_{n \to \infty} x_n = x.$

</details>

### Example: Using the Comparison Theorem

**Lila:** Can we use this theorem on an example we already know, like $\tfrac{n}{n+1} \to 1$?

**Acharya Bhaskar:** Excellent idea. Let’s try.  

We want to prove  
$$\lim_{n \to \infty} \frac{n}{n+1} = 1.$$

First compute the error:  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| = \frac{1}{n+1}.$$

Now notice that  
$$\frac{1}{n+1} \leq \frac{1}{n} \quad \text{for all } n \geq 1.$$

So we can set $a_n = \tfrac{1}{n}$, which we already know tends to $0$, and take $C = 1$.  
Then the condition of the theorem is satisfied:  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| \leq 1 \cdot a_n.$$

By the theorem,  
$$\lim_{n \to \infty} \frac{n}{n+1} = 1.$$

---

**Lila:** Wow, that was much quicker than the direct $\varepsilon$–$N$ proof we did earlier.

**Acharya Bhaskar:** Exactly. This theorem saves us effort. Once you have a few standard sequences like $\tfrac{1}{n}$ or $\tfrac{1}{n^2}$ whose limits you know, you can use them as benchmarks to prove many others.

### Example: A Rational Limit with the Comparison Theorem

**Lila:** Can we also use the theorem for something that looks a bit more complicated, like  
$$x_n = \frac{2n+3}{5n+1}?$$

**Acharya Bhaskar:** Certainly. We already proved directly that  
$$\lim_{n \to \infty} \frac{2n+3}{5n+1} = \frac{2}{5}.$$  
Let’s see how the comparison theorem helps.

First, compute the error:  
\[
\frac{2n+3}{5n+1} - \frac{2}{5} = \frac{13}{25n+5}.
\]

So,  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| = \frac{13}{25n+5}.$$

Now notice that for all $n \geq 1$,  
$$\frac{13}{25n+5} \leq \frac{13}{25n} = \frac{13}{25}\cdot \frac{1}{n}.$$

So we can set $a_n = \tfrac{1}{n}$ (which goes to $0$) and $C = \tfrac{13}{25}$.  
Then  
$$|x_n - \tfrac{2}{5}| \leq C \, a_n.$$

By the theorem,  
$$\lim_{n \to \infty} \frac{2n+3}{5n+1} = \frac{2}{5}.$$

---

**Lila:** That really simplifies things! Instead of wrestling with inequalities, we just compare to $\tfrac{1}{n}$.

**Acharya Bhaskar:** Exactly. This method is especially powerful for rational sequences, where the error often turns into a constant times $\tfrac{1}{n}$.

### Example: Proving $\lim_{n \to \infty} c^{1/n} = 1$ for $c > 0$

**Lila:** I’ve seen the sequence $c^{1/n}$ before. Does it always converge to $1$ for positive $c$?

**Acharya Bhaskar:** Exactly right. No matter what positive number $c$ is, when you take its $n$-th root and let $n$ grow, the sequence converges to $1$.

**Lila:** Even if $c$ is really big, like $1000$?

**Acharya Bhaskar:** Yes. Think of it this way: the $n$-th root of any number becomes closer and closer to $1$ as $n$ grows, because taking more and more roots flattens things out.

---

<details>
<summary>Click to see the proof</summary>

We want to prove that for every $\varepsilon > 0$, there exists $N$ such that for all $n > N$,  
$$|c^{1/n} - 1| < \varepsilon.$$

---

**Case 1: $c = 1$.**  
Then $c^{1/n} = 1$ for all $n$, so the limit is trivially $1$.

---

**Case 2: $c > 1$.**  

Take logarithms. Define  
$$x_n = c^{1/n}.$$  
Then  
$$\ln(x_n) = \frac{1}{n} \ln c.$$  

Since $\tfrac{1}{n} \to 0$, it follows that $\ln(x_n) \to 0$.  
Therefore, $x_n = e^{\ln(x_n)} \to e^0 = 1$.

---

**Case 3: $0 < c < 1$.**  

Write $c = \tfrac{1}{d}$ where $d > 1$. Then  
$$c^{1/n} = \left(\frac{1}{d}\right)^{1/n} = \frac{1}{d^{1/n}}.$$  

But from Case 2, $d^{1/n} \to 1$, so $\tfrac{1}{d^{1/n}} \to \tfrac{1}{1} = 1$.

---

Thus, in all cases $c^{1/n} \to 1$ for $c > 0$. ✅

</details>

**Lila:** That’s elegant! So taking logarithms made the proof really clean.

**Acharya Bhaskar:** Exactly. Logarithms are often the right tool when exponents or roots are involved. We’ll see this trick again later.
