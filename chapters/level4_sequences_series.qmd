# Level 4: Sequences and Series

## Introduction

**Lila:** Acharya, until now we have been exploring real numbers, their representations, and Cantor’s ideas. But what comes next in our journey?

**Acharya Bhaskar:** A natural next step, Lila, is to study not just *individual* numbers, but *patterns* of numbers — how they progress, how they accumulate. This leads us to the study of **sequences** and **series**.

---

## What is a sequence?

**Lila:** What exactly is a sequence?

**Acharya Bhaskar:** A **sequence** is simply an ordered list of numbers:
$$
(a_n)_{n=1}^\infty = a_1, a_2, a_3, \dots
$$
Each $a_n$ is called the *$n$-th term*. The idea is that as $n$ increases, we can watch how the terms behave — whether they approach a limit, oscillate, or grow without bound.

**Lila:** So a sequence is like watching numbers march along, step by step?

**Acharya Bhaskar:** Exactly! For example:
- $a_n = \tfrac{1}{n}$ gives the sequence $1, \tfrac{1}{2}, \tfrac{1}{3}, \dots$ which gets closer and closer to $0$.  
- $a_n = (-1)^n$ gives $-1, 1, -1, 1, \dots$ which jumps back and forth and never settles.

---

## What is a series?

**Lila:** And what about a series?

**Acharya Bhaskar:** A **series** is what we get when we add up the terms of a sequence:
$$
S = \sum_{n=1}^\infty a_n = a_1 + a_2 + a_3 + \cdots
$$

**Lila:** So if a sequence is footsteps, then a series is like adding the total distance covered?

**Acharya Bhaskar:** Well said! For example:
- The series $\sum_{n=1}^\infty \tfrac{1}{2^n} = \tfrac{1}{2} + \tfrac{1}{4} + \tfrac{1}{8} + \cdots$ converges to $1$.  
- But the series $\sum_{n=1}^\infty \tfrac{1}{n} = 1 + \tfrac{1}{2} + \tfrac{1}{3} + \cdots$ grows without bound — it diverges.

---

## Why study sequences and series?

**Lila:** Why are these so important?

**Acharya Bhaskar:** Because they are the language of approximation and analysis: 
1. Important numbers like $e$ and $\pi$ appear as limits of sequences or sums of series.  
2. Functions like $\sin x$, $\cos x$, and $e^x$ can be expressed as infinite series — that’s how we calculate them on computers!  
3. Understanding limits of sequences helps us define continuity, derivatives, and integrals.  

**Lila:** So sequences and series are the foundation stones for the rest of calculus and analysis.

**Acharya Bhaskar:** Precisely. Real analysis begins here, with the careful study of how infinite processes behave.

---

**Acharya Bhaskar (teaser):**  
“Think of a sequence as footsteps marching towards a destination.  
If the footsteps wander endlessly, the sequence diverges.  
If they march steadily towards a point, the sequence converges.  
And when you add the footsteps together, you create the story of a series.”  
## Limits of Sequences

**Lila:** Acharya, you said some sequences “converge” and some “diverge.” What exactly does it mean for a sequence to converge?

**Acharya Bhaskar:** Good question, Lila. Intuitively, a sequence **converges** if its terms get closer and closer to some fixed number, which we call the **limit**.

**Lila:** So for $a_n = \tfrac{1}{n}$, the terms $1, \tfrac{1}{2}, \tfrac{1}{3}, \dots$ get closer and closer to $0$, so the limit should be $0$?

**Acharya Bhaskar:** Exactly. We write
$$
\lim_{n\to\infty} \frac{1}{n} = 0.
$$

---

### The formal definition

**Acharya Bhaskar:** But in real analysis we need precision. So here is the definition:

A sequence $(a_n)$ is said to converge to a number $L$ if for every $\varepsilon > 0$, there exists a natural number $K(\varepsilon)$ such that whenever $n \geq K(\varepsilon)$, we have
$$
|a_n - L| < \varepsilon.
$$

**Lila:** Let me see if I understand. This means: no matter how small an error margin $\varepsilon$ I choose, if I go far enough in the sequence (beyond some $K$ that depends on the given $\varepsilon$), all terms stay within that margin around $L$.

**Acharya Bhaskar:** Well said. That is the precise meaning of convergence.

---

**Example:** $a_n = \tfrac{1}{n}$

**Lila:** Could we test this definition with $a_n = \tfrac{1}{n}$ and $L=0$?

**Acharya Bhaskar:** Certainly.  
We want: for every $\varepsilon>0$, find $K(\varepsilon)$ such that if $n\ge K(\varepsilon)$, then $|\tfrac{1}{n} - 0| < \varepsilon$.  
But $|\tfrac{1}{n} - 0| = \tfrac{1}{n}$.  
So we require $\tfrac{1}{n} < \varepsilon$.  

This is the same as $n > \tfrac{1}{\varepsilon}$.  
So if we choose $K(\varepsilon) = \lceil \tfrac{1}{\varepsilon}\rceil$, then for all $n\ge K(\varepsilon)$, the condition is satisfied.

**Lila:** That works! So the formal definition confirms that $\tfrac{1}{n} \to 0$.

---

**Example:** $a_n = (-1)^n$

**Lila:** And what about $a_n = (-1)^n$?

**Acharya Bhaskar:** Then the terms alternate $-1, 1, -1, 1, \dots$. Do they get closer to a single value?

**Lila:** No — they keep jumping back and forth. So this sequence does **not** converge.

**Acharya Bhaskar:** Correct. It diverges, because there is no single $L$ that the terms approach.

---

### Why limits matter

**Lila:** So convergence is about sequences approaching a fixed target. But why is this so important?

**Acharya Bhaskar:** Because the notion of **limit** is the cornerstone of analysis. Continuity, derivatives, integrals, and infinite series all depend on it. Mastering limits of sequences is the first step toward the deeper structures of calculus.  

**Limit of a function via sequences**

::: {.callout-note collapse="true"}
## Connecting sequence limits and function limits

**Lila:** Acharya, I understand the limit of a sequence. But what could the limit of sequences have to do with the notion of limits of functions?

**Acharya Bhaskar:** An excellent question, Lila. In fact, the two ideas are deeply connected.  

We say
$$
\lim_{x\to a} f(x) = L
$$
if and only if for **every sequence** $(x_n)$ with $x_n \to a$ and $x_n \neq a$, the sequence $(f(x_n))$ converges to $L$.

---

**Lila:** So if all possible sequences approaching $a$ give the same limiting value $L$ for $f(x_n)$, then that must be the limit of the function?

**Acharya Bhaskar:** Exactly. This is called the *sequential criterion* for functional limits.  

It tells us: instead of thinking about all the infinitely many “ways” of approaching $a$, it is enough to test every possible sequence converging to $a$.

---

**Lila:** Ah! So the concept of a function limit is really an extension of the idea of sequence limits.

**Acharya Bhaskar:** Precisely, Lila. That is why we first built a strong foundation with sequences — they are the key to understanding limits of functions.
:::

### Another Example of Convergence

**Lila:** We proved earlier that $\lim \tfrac{1}{n} = 0$. Could you show me another example, maybe a slightly different sequence?

**Acharya Bhaskar:** Certainly! Let’s consider the sequence  
$$x_n = \frac{1}{n^2+1}.$$
I claim that $\lim_{n \to \infty} x_n = 0$.

**Lila:** Oh, it looks similar to $\tfrac{1}{n}$, but the denominator grows even faster. So it should also go to zero, right?

**Acharya Bhaskar:** Exactly. Let’s do a rigorous $\varepsilon$–$N$ proof.

<details>
<summary>Click to see the proof</summary>

We want to show that for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$\Bigg|\frac{1}{n^2+1} - 0\Bigg| < \varepsilon.$$

But  
$$\Bigg|\frac{1}{n^2+1}\Bigg| = \frac{1}{n^2+1}.$$

Notice that  
$$\frac{1}{n^2+1} < \frac{1}{n^2}.$$

So it is enough to require  
$$\frac{1}{n^2} < \varepsilon.$$

This means  
$$n^2 > \frac{1}{\varepsilon}, \quad \text{or equivalently} \quad n > \frac{1}{\sqrt{\varepsilon}}.$$

Thus, if we choose  
$$N = \left\lceil \frac{1}{\sqrt{\varepsilon}} \right\rceil,$$  
then for all $n > N$,  
$$\frac{1}{n^2+1} < \varepsilon.$$

Hence,  
$$\lim_{n \to \infty} \frac{1}{n^2+1} = 0.$$

</details>

**Lila:** That was neat! So the idea is the same as before, but we had to be careful with the square root this time.

**Acharya Bhaskar:** Exactly. You’ll see that many convergence proofs follow a similar structure. The challenge is usually in rearranging inequalities smartly.

---

### A Non–Zero Limit Example

**Lila:** So far, the examples we’ve done all go to zero. Can you show me a sequence that converges to something other than zero?

**Acharya Bhaskar:** Of course. Let’s look at  
$$x_n = \frac{n}{n+1}.$$

I claim that  
$$\lim_{n \to \infty} \frac{n}{n+1} = 1.$$

**Lila:** Hmm… when $n$ is large, $n+1$ is almost the same as $n$, so $\tfrac{n}{n+1}$ should be almost $1$.

**Acharya Bhaskar:** Exactly. Now let’s prove it formally.

<details>
<summary>Click to see the proof</summary>

We want to show: for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| < \varepsilon.$$

Simplify the difference:  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| = \Bigg|\frac{n - (n+1)}{n+1}\Bigg| = \frac{1}{n+1}.$$

So we need  
$$\frac{1}{n+1} < \varepsilon.$$

That is,  
$$n+1 > \frac{1}{\varepsilon} \quad \implies \quad n > \frac{1}{\varepsilon} - 1.$$

Thus, if we choose  
$$N = \left\lceil \frac{1}{\varepsilon} - 1 \right\rceil,$$  
then for all $n > N$,  
$$\Bigg|\frac{n}{n+1} - 1\Bigg| < \varepsilon.$$

Therefore,  
$$\lim_{n \to \infty} \frac{n}{n+1} = 1.$$

</details>

**Lila:** That was nice! The sequence actually climbs closer and closer to $1$, never quite reaching it, but the proof shows it really does converge there.

**Acharya Bhaskar:** Exactly. This illustrates an important point — limits don’t always have to be zero; the same method works for any real number.

### Convergence to a Rational Number

**Lila:** We’ve seen limits going to $0$ and $1$. Can a sequence converge to some other fraction, like $\tfrac{2}{5}$?

**Acharya Bhaskar:** Absolutely! Let’s take  
$$x_n = \frac{2n+3}{5n+1}.$$

I claim that  
$$\lim_{n \to \infty} \frac{2n+3}{5n+1} = \frac{2}{5}.$$

**Lila:** I can guess why — the higher powers of $n$ dominate, so it’s like $\tfrac{2n}{5n} = \tfrac{2}{5}$ when $n$ is large.

**Acharya Bhaskar:** That’s the intuition. Let’s now prove it rigorously.

<details>
<summary>Click to see the proof</summary>

We want to show: for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| < \varepsilon.$$

Simplify the difference:  
$$
\frac{2n+3}{5n+1} - \frac{2}{5}
= \frac{5(2n+3) - 2(5n+1)}{5(5n+1)}
= \frac{10n+15 - 10n - 2}{25n+5}
= \frac{13}{25n+5}.
$$

So  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| = \frac{13}{25n+5}.$$

Now, we want  
$$\frac{13}{25n+5} < \varepsilon.$$

This inequality is equivalent to  
$$25n+5 > \frac{13}{\varepsilon} \quad \implies \quad n > \frac{13}{25\varepsilon} - \frac{1}{5}.$$

So we can choose  
$$N = \left\lceil \frac{13}{25\varepsilon} - \frac{1}{5} \right\rceil.$$

Then for all $n > N$, we have  
$$\Bigg|\frac{2n+3}{5n+1} - \frac{2}{5}\Bigg| < \varepsilon.$$

Therefore,  
$$\lim_{n \to \infty} \frac{2n+3}{5n+1} = \frac{2}{5}.$$

</details>

**Lila:** I see! The algebra looks a bit longer, but the same method works. The main trick was simplifying the difference.

**Acharya Bhaskar:** Precisely. Once you bring it into a simple form, the $\varepsilon$–$N$ argument falls into place. This shows that sequences can converge to any real number, not just $0$ or $1$.

### An Example of Divergence

**Lila:** All the examples so far show sequences settling to a finite number. But what about a sequence that *doesn’t* converge?  

**Acharya Bhaskar:** Excellent question. Consider the sequence  
$$x_n = n.$$

**Lila:** That just grows bigger and bigger! So it can’t converge to a real number, right?

**Acharya Bhaskar:** Exactly. Formally, we say it *diverges to infinity*. Let’s make this precise.

<details>
<summary>Click to see the explanation</summary>

To say that $\lim_{n \to \infty} x_n = +\infty$ means:  

For every real number $M > 0$, there exists $N \in \mathbb{N}$ such that for all $n > N$,  
$$x_n > M.$$

Now, since $x_n = n$, if you give me any $M > 0$, I can simply choose  
$$N = \lceil M \rceil.$$  

Then for all $n > N$, clearly $n > M$, so $x_n > M$.  

Thus, the sequence $\{n\}$ does not converge to a finite limit, but instead diverges to infinity.  

</details>

**Lila:** So divergence isn’t just “no limit at all.” Sometimes it means the sequence goes off to infinity in a systematic way.  

**Acharya Bhaskar:** Exactly. There are also examples where sequences oscillate and fail to have any limit at all — those are divergent in a different sense.  

### An Oscillating Divergent Sequence

**Lila:** You said some sequences can diverge by oscillating. Can you show me an example?

**Acharya Bhaskar:** Certainly. Consider the sequence  
$$x_n = (-1)^n.$$

**Lila:** Oh, so it goes like $-1, +1, -1, +1, \dots$ That never settles down to a single number.

**Acharya Bhaskar:** Exactly. Let’s explain why it does **not** converge.

<details>
<summary>Click to see the explanation</summary>

Suppose, for contradiction, that $\lim_{n \to \infty} (-1)^n = L$ for some real number $L$.  

Then by the definition of convergence, for every $\varepsilon > 0$ there should be an $N$ such that for all $n > N$,  
$$|(-1)^n - L| < \varepsilon.$$

But notice:  
- If $n$ is even, $(-1)^n = 1$.  
- If $n$ is odd, $(-1)^n = -1$.  

So the sequence keeps jumping between $1$ and $-1$, no matter how large $n$ becomes.  

For example, if we take $\varepsilon = \tfrac{1}{2}$, then the condition requires all terms $(-1)^n$ to lie within an interval of radius $\tfrac{1}{2}$ around $L$.  

But one subsequence is constantly $1$, and the other is constantly $-1$. These two points are $2$ units apart, which is much larger than $\tfrac{1}{2}$.  

Therefore, no single $L$ can satisfy the definition. The sequence does **not converge**.

</details>

**Lila:** I see! Unlike $n$, which runs off to infinity, this one just keeps bouncing forever without settling.

**Acharya Bhaskar:** Precisely. These two examples — $x_n = n$ and $x_n = (-1)^n$ — illustrate two common ways in which sequences can fail to converge.
